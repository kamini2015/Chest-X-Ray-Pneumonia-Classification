{
  "metadata": {
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 23812,
          "sourceType": "datasetVersion",
          "datasetId": 17810
        }
      ],
      "dockerImageVersionId": 30664,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "source": [
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = ':https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F17810%2F23812%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240310%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240310T210456Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D05156f30e0295090c797dcf3a704d5045ec7c329affdf5ba3cf0e8038b3f2c1abac1496b3751141fa87b906d4fe20567226079f5b5fd3c28238d1fbf61bed13a4a0262c85df34028a81cea84eab5319550e22acaaba0c00778f6e8b39fc7771dc6b66206582e4697d02eabf8cf32780ac5a0d2f49c587a7f7c240dab95785db7387cde3efe58866278d8d686f55a2b38148092d35c35ba1fb25dd887cac07f69bd350aa9ab4c362fd0f85bc9d36b3c58281d27a7f1bd6b8d852bc40ef70195f26f1e791db24f8f28b4953fe004277de0c450a912650faa378c64e06f25857982a567e66afbd4ef56fcca0779c2023aa827bcddc4ced5259c97f04c309426d264'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "0rTXmilYLtoA"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <p style=\"font-family:newtimeroman;font-size:150%;text-align:center;color:#6A5ACD;\">Chest X-Ray Classification | Xception | 98% </p>"
      ],
      "metadata": {
        "id": "hqonzaNYLtoC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Chest X-Ray (1).png](attachment:7e662cec-4fcf-4ec5-bcdd-482a83bf6361.png)"
      ],
      "metadata": {
        "id": "mlxLmaRaLtoF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <p style=\"font-family:newtimeroman;font-size:150%;text-align:center;color:#6A5ACD;\">Importing Libraries</p>"
      ],
      "metadata": {
        "id": "9XgxhcuTLtoH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Import Os and Basis Libraries\n",
        "import cv2\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "#Matplot Images\n",
        "import matplotlib.image as mpimg\n",
        "# Tensflor and Keras Layer and Model and Optimize and Loss\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import Sequential\n",
        "from keras.layers import *\n",
        "from tensorflow.keras.losses import BinaryCrossentropy\n",
        "#Kernel Intilizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "# import tensorflow_hub as hub\n",
        "from tensorflow.keras.optimizers import Adam , Adamax\n",
        "#PreTrained Model\n",
        "from tensorflow.keras.applications import *\n",
        "#Early Stopping\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "# Warnings Remove\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-03T18:07:42.272762Z",
          "iopub.execute_input": "2024-03-03T18:07:42.273394Z",
          "iopub.status.idle": "2024-03-03T18:07:42.282544Z",
          "shell.execute_reply.started": "2024-03-03T18:07:42.273363Z",
          "shell.execute_reply": "2024-03-03T18:07:42.281627Z"
        },
        "trusted": true,
        "id": "ydNk3CpzLtoH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <p style=\"font-family:newtimeroman;font-size:150%;text-align:center;color:#6A5ACD;\">Load Data</p>"
      ],
      "metadata": {
        "id": "kfW7p-ymLtoI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Directory containing the \"Train\" folder\n",
        "directory = \"/kaggle/input/chest-xray-pneumonia/chest_xray/train\"\n",
        "\n",
        "filepath =[]\n",
        "label = []\n",
        "\n",
        "folds = os.listdir(directory)\n",
        "\n",
        "for fold in folds:\n",
        "    f_path = os.path.join(directory , fold)\n",
        "\n",
        "    imgs = os.listdir(f_path)\n",
        "\n",
        "    for img in imgs:\n",
        "\n",
        "        img_path = os.path.join(f_path , img)\n",
        "        filepath.append(img_path)\n",
        "        label.append(fold)\n",
        "\n",
        "#Concat data paths with labels\n",
        "file_path_series = pd.Series(filepath , name= 'filepath')\n",
        "Label_path_series = pd.Series(label , name = 'label')\n",
        "df_train = pd.concat([file_path_series ,Label_path_series ] , axis = 1)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-03T18:07:42.321478Z",
          "iopub.execute_input": "2024-03-03T18:07:42.321752Z",
          "iopub.status.idle": "2024-03-03T18:07:42.486306Z",
          "shell.execute_reply.started": "2024-03-03T18:07:42.321729Z",
          "shell.execute_reply": "2024-03-03T18:07:42.485244Z"
        },
        "trusted": true,
        "id": "qMQ_X_CGLtoI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Head\n",
        "df_train"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-03T18:07:42.488003Z",
          "iopub.execute_input": "2024-03-03T18:07:42.48882Z",
          "iopub.status.idle": "2024-03-03T18:07:42.507308Z",
          "shell.execute_reply.started": "2024-03-03T18:07:42.488787Z",
          "shell.execute_reply": "2024-03-03T18:07:42.506231Z"
        },
        "trusted": true,
        "id": "OgkALxWvLtoJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Directory containing the \"Train\" folder\n",
        "directory = \"/kaggle/input/chest-xray-pneumonia/chest_xray/test\"\n",
        "\n",
        "filepath =[]\n",
        "label = []\n",
        "\n",
        "folds = os.listdir(directory)\n",
        "\n",
        "for fold in folds:\n",
        "    f_path = os.path.join(directory , fold)\n",
        "\n",
        "    imgs = os.listdir(f_path)\n",
        "\n",
        "    for img in imgs:\n",
        "\n",
        "        img_path = os.path.join(f_path , img)\n",
        "        filepath.append(img_path)\n",
        "        label.append(fold)\n",
        "\n",
        "#Concat data paths with labels\n",
        "file_path_series = pd.Series(filepath , name= 'filepath')\n",
        "Label_path_series = pd.Series(label , name = 'label')\n",
        "df_test = pd.concat([file_path_series ,Label_path_series ] , axis = 1)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-03T18:07:42.508249Z",
          "iopub.execute_input": "2024-03-03T18:07:42.508552Z",
          "iopub.status.idle": "2024-03-03T18:07:42.621883Z",
          "shell.execute_reply.started": "2024-03-03T18:07:42.508529Z",
          "shell.execute_reply": "2024-03-03T18:07:42.621113Z"
        },
        "trusted": true,
        "id": "3Gq0ZgriLtoJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Head\n",
        "df_test.sample(5)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-03T18:07:42.623776Z",
          "iopub.execute_input": "2024-03-03T18:07:42.624083Z",
          "iopub.status.idle": "2024-03-03T18:07:42.635124Z",
          "shell.execute_reply.started": "2024-03-03T18:07:42.624058Z",
          "shell.execute_reply": "2024-03-03T18:07:42.634133Z"
        },
        "trusted": true,
        "id": "7PgBWVlBLtoJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Shape\n",
        "print(f\"The shape of The Train data is: {df_train.shape}\")\n",
        "print(f\"The shape of The Test data is: {df_test.shape}\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-03T18:07:42.636478Z",
          "iopub.execute_input": "2024-03-03T18:07:42.636821Z",
          "iopub.status.idle": "2024-03-03T18:07:42.645954Z",
          "shell.execute_reply.started": "2024-03-03T18:07:42.636772Z",
          "shell.execute_reply": "2024-03-03T18:07:42.64509Z"
        },
        "trusted": true,
        "id": "a_gr0g0gLtoK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <p style=\"font-family:newtimeroman;font-size:150%;text-align:center;color:#6A5ACD;\">Making Train Test And Validation Datasets</p>"
      ],
      "metadata": {
        "id": "J0IUTQUzLtoK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Data_Dir\n",
        "data_dir = '/kaggle/input/chest-xray-pneumonia/chest_xray/train'\n",
        "test_dir = '/kaggle/input/chest-xray-pneumonia/chest_xray/test'\n",
        "\n",
        "IMAGE_SIZE = (256,256)\n",
        "\n",
        "print('Training Images:')\n",
        "# Creating the training dataset\n",
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    data_dir,\n",
        "    validation_split=0.1,\n",
        "    subset='training',\n",
        "    seed=123,\n",
        "    image_size=IMAGE_SIZE,\n",
        "    batch_size=32)\n",
        "\n",
        "#Testing  Data\n",
        "print('Validation Images:')\n",
        "validation_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    data_dir,\n",
        "    validation_split=0.1,\n",
        "    subset='validation',\n",
        "    seed=123,\n",
        "    image_size=IMAGE_SIZE,\n",
        "    batch_size=32)\n",
        "\n",
        "print('Testing Images:')\n",
        "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    test_dir,\n",
        "    seed=123,\n",
        "    image_size=IMAGE_SIZE,\n",
        "    batch_size=32)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-03T18:20:37.136647Z",
          "iopub.execute_input": "2024-03-03T18:20:37.137513Z",
          "iopub.status.idle": "2024-03-03T18:20:39.373037Z",
          "shell.execute_reply.started": "2024-03-03T18:20:37.137479Z",
          "shell.execute_reply": "2024-03-03T18:20:39.372312Z"
        },
        "trusted": true,
        "id": "sITELCzpLtoL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <p style=\"font-family:newtimeroman;font-size:150%;text-align:center;color:#6A5ACD;\">Encoding Labels</p>\n"
      ],
      "metadata": {
        "id": "5CSZ25zQLtoL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract labels\n",
        "train_labels = train_ds.class_names\n",
        "test_labels = test_ds.class_names\n",
        "validation_labels = validation_ds.class_names\n",
        "\n",
        "# Encode Labels\n",
        "\n",
        "# Define your class labels\n",
        "class_labels = ['NORMAL', 'PNEUMONIA']\n",
        "\n",
        "# Instantiate LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# Fit label encoder on the class labels\n",
        "label_encoder.fit(class_labels)\n",
        "\n",
        "# Transform the labels for training dataset\n",
        "train_labels_encoded = label_encoder.transform(train_labels)\n",
        "\n",
        "# Transform the labels for validation dataset\n",
        "validation_labels_encoded = label_encoder.transform(validation_labels)\n",
        "\n",
        "# Transform the labels for test dataset\n",
        "test_labels_encoded = label_encoder.transform(test_labels)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-03T18:20:39.449557Z",
          "iopub.execute_input": "2024-03-03T18:20:39.450156Z",
          "iopub.status.idle": "2024-03-03T18:20:39.45594Z",
          "shell.execute_reply.started": "2024-03-03T18:20:39.450127Z",
          "shell.execute_reply": "2024-03-03T18:20:39.455069Z"
        },
        "trusted": true,
        "id": "ZibZXsaILtoL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Shape of the dataset\n",
        "for image_batch, labels_batch in train_ds:\n",
        "    print(\"Shape of X_train: \", image_batch.shape)\n",
        "    print(\"Shape of y_train: \", labels_batch.shape)\n",
        "    break"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-03T18:07:49.485787Z",
          "iopub.execute_input": "2024-03-03T18:07:49.486134Z",
          "iopub.status.idle": "2024-03-03T18:07:51.043828Z",
          "shell.execute_reply.started": "2024-03-03T18:07:49.486104Z",
          "shell.execute_reply": "2024-03-03T18:07:51.042908Z"
        },
        "trusted": true,
        "id": "zOJqh56OLtoL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <p style=\"font-family:newtimeroman;font-size:150%;text-align:center;color:#6A5ACD;\">Normalizing Pixel Value</p>\n"
      ],
      "metadata": {
        "id": "ovgAS8K3LtoM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalizing Pixel Values\n",
        "\n",
        "# Train Data\n",
        "train_ds = train_ds.map(lambda x, y: (x / 255.0, y))\n",
        "# Val Data\n",
        "validation_ds = validation_ds.map(lambda x, y: (x / 255.0, y))\n",
        "# Test Data\n",
        "test_ds = test_ds.map(lambda x, y: (x / 255.0, y))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-03T18:20:42.352884Z",
          "iopub.execute_input": "2024-03-03T18:20:42.353517Z",
          "iopub.status.idle": "2024-03-03T18:20:42.384575Z",
          "shell.execute_reply.started": "2024-03-03T18:20:42.353484Z",
          "shell.execute_reply": "2024-03-03T18:20:42.383795Z"
        },
        "trusted": true,
        "id": "u658D6BELtoM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <p style=\"font-family:newtimeroman;font-size:150%;text-align:center;color:#6A5ACD;\">Visual Count of Train Label</p>\n"
      ],
      "metadata": {
        "id": "IfaeGcWaLtoM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Count the occurrences of each category in the 'category' column\n",
        "count = df_train['label'].value_counts()\n",
        "\n",
        "# Create a figure with two subplots\n",
        "fig, axs = plt.subplots(1, 2, figsize=(12, 6), facecolor='white')\n",
        "\n",
        "# Plot pie chart on the first subplot\n",
        "palette = sns.color_palette(\"viridis\")\n",
        "sns.set_palette(palette)\n",
        "axs[0].pie(count, labels=count.index, autopct='%1.1f%%', startangle=140)\n",
        "axs[0].set_title('Distribution of Categories')\n",
        "\n",
        "# Plot bar chart on the second subplot\n",
        "sns.barplot(x=count.index, y=count.values, ax=axs[1], palette=\"viridis\")\n",
        "axs[1].set_title('Count of Categories')\n",
        "\n",
        "# Adjust layout\n",
        "plt.tight_layout()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-03T18:07:51.123879Z",
          "iopub.execute_input": "2024-03-03T18:07:51.124182Z",
          "iopub.status.idle": "2024-03-03T18:07:51.473302Z",
          "shell.execute_reply.started": "2024-03-03T18:07:51.124158Z",
          "shell.execute_reply": "2024-03-03T18:07:51.472396Z"
        },
        "trusted": true,
        "id": "NaIyNcjsLtoM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <p style=\"font-family:newtimeroman;font-size:150%;text-align:center;color:#6A5ACD;\">Visual Count of Test Label</p>\n"
      ],
      "metadata": {
        "id": "m4PZDPmQLtoM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Count the occurrences of each category in the 'category' column\n",
        "count = df_test['label'].value_counts()\n",
        "\n",
        "# Create a figure with two subplots\n",
        "fig, axs = plt.subplots(1, 2, figsize=(12, 6), facecolor='white')\n",
        "\n",
        "# Plot pie chart on the first subplot\n",
        "palette = sns.color_palette(\"viridis\")\n",
        "sns.set_palette(palette)\n",
        "axs[0].pie(count, labels=count.index, autopct='%1.1f%%', startangle=140)\n",
        "axs[0].set_title('Distribution of Categories')\n",
        "\n",
        "# Plot bar chart on the second subplot\n",
        "sns.barplot(x=count.index, y=count.values, ax=axs[1], palette=\"viridis\")\n",
        "axs[1].set_title('Count of Categories')\n",
        "\n",
        "# Adjust layout\n",
        "plt.tight_layout()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-03T18:07:51.474493Z",
          "iopub.execute_input": "2024-03-03T18:07:51.474813Z",
          "iopub.status.idle": "2024-03-03T18:07:51.794828Z",
          "shell.execute_reply.started": "2024-03-03T18:07:51.474786Z",
          "shell.execute_reply": "2024-03-03T18:07:51.793704Z"
        },
        "trusted": true,
        "id": "PqdnheWDLtoN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <p style=\"font-family:newtimeroman;font-size:150%;text-align:center;color:#6A5ACD;\">Visualizing Train Images</p>"
      ],
      "metadata": {
        "id": "AvU1auw2LtoN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_images(path, num_images=5):\n",
        "    # Get a list of image filenames in the specified path\n",
        "    image_filenames = os.listdir(path)\n",
        "\n",
        "    # Limit the number of images to visualize if there are more than num_images\n",
        "    num_images = min(num_images, len(image_filenames))\n",
        "\n",
        "    # Create a figure and axis object to display images\n",
        "    fig, axes = plt.subplots(1, num_images, figsize=(15, 3),facecolor='white')\n",
        "\n",
        "    # Iterate over the selected images and display them\n",
        "    for i, image_filename in enumerate(image_filenames[:num_images]):\n",
        "        # Load the image using Matplotlib\n",
        "        image_path = os.path.join(path, image_filename)\n",
        "        image = mpimg.imread(image_path)\n",
        "\n",
        "        # Display the image\n",
        "        axes[i].imshow(image)\n",
        "        axes[i].axis('off')  # Turn off axis\n",
        "        axes[i].set_title(image_filename)  # Set image filename as title\n",
        "\n",
        "    # Adjust layout and display the figure\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-03T18:07:51.796127Z",
          "iopub.execute_input": "2024-03-03T18:07:51.79648Z",
          "iopub.status.idle": "2024-03-03T18:07:51.804315Z",
          "shell.execute_reply.started": "2024-03-03T18:07:51.796452Z",
          "shell.execute_reply": "2024-03-03T18:07:51.803231Z"
        },
        "trusted": true,
        "id": "Egcw_wCXLtoN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### **<h1 align=\"center\"><span style=\"color:#6A5ACD;\">NORMAL Images</span>**"
      ],
      "metadata": {
        "id": "v0SSBJDGLtoN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify the path containing the images to visualize\n",
        "path_to_visualize = \"/kaggle/input/chest-xray-pneumonia/chest_xray/train/NORMAL\"\n",
        "\n",
        "# Visualize some images from the specified path\n",
        "visualize_images(path_to_visualize, num_images=5)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-03T18:07:51.805724Z",
          "iopub.execute_input": "2024-03-03T18:07:51.806353Z",
          "iopub.status.idle": "2024-03-03T18:07:52.904443Z",
          "shell.execute_reply.started": "2024-03-03T18:07:51.806319Z",
          "shell.execute_reply": "2024-03-03T18:07:52.903335Z"
        },
        "trusted": true,
        "id": "BpzQMNrcLtoN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### **<h1 align=\"center\"><span style=\"color:#6A5ACD;\">PNEUMONIA Images</span>**"
      ],
      "metadata": {
        "id": "hiaJzfE7LtoN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify the path containing the images to visualize\n",
        "path_to_visualize = \"/kaggle/input/chest-xray-pneumonia/chest_xray/train/PNEUMONIA\"\n",
        "\n",
        "# Visualize some images from the specified path\n",
        "visualize_images(path_to_visualize, num_images=5)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-03T18:07:52.905958Z",
          "iopub.execute_input": "2024-03-03T18:07:52.90633Z",
          "iopub.status.idle": "2024-03-03T18:07:53.814114Z",
          "shell.execute_reply.started": "2024-03-03T18:07:52.906297Z",
          "shell.execute_reply": "2024-03-03T18:07:53.813217Z"
        },
        "trusted": true,
        "id": "2VvUgMK4LtoN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <p style=\"font-family:newtimeroman;font-size:150%;text-align:center;color:#6A5ACD;\">Model Building</p>"
      ],
      "metadata": {
        "id": "1gHogOGILtoO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### **<h1 align=\"center\"><span style=\"color:#6A5ACD;\">Transfer Learning</span>**\n",
        "    \n",
        "**Transfer learning is a machine learning technique where knowledge gained from training one model is applied to a different but related task. Instead of starting from scratch, a pre-trained model is used as a starting point. By leveraging features learned during the training of the pre-trained model, the new model can achieve better performance with less data and computation. This approach is particularly useful when working with limited labeled data or computational resources. Transfer learning involves fine-tuning the pre-trained model by adjusting its parameters to better suit the new task. This process allows for faster convergence and improved generalization to the new task. Overall, transfer learning accelerates the development of models for various tasks by capitalizing on the knowledge learned from previous tasks.**"
      ],
      "metadata": {
        "id": "HYN0GhffLtoO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "1. `base_model = Xception(weights='imagenet', include_top=False, pooling='avg', input_shape=(256, 256, 3))`:\n",
        "   - `Xception`: This loads the Xception model architecture, a deep convolutional neural network, which is pre-trained on the ImageNet dataset.\n",
        "   - `weights='imagenet'`: Specifies that the model should be initialized with pre-trained weights from the ImageNet dataset.\n",
        "   - `include_top=False`: Excludes the top (classification) layer of the model, which allows us to add our own custom classification layers.\n",
        "   - `pooling='avg'`: Uses global average pooling to convert the 3D output tensor of the base model into a 1D tensor.\n",
        "   - `input_shape=(256, 256, 3)`: Specifies the input shape of the images expected by the model.\n",
        "\n",
        "2. `base_model.trainable = False`:\n",
        "   - Freezes the layers in the base model, preventing them from being updated during training.\n",
        "\n",
        "3. `model = Sequential()`:\n",
        "   - Initializes a sequential model where layers are added sequentially.\n",
        "\n",
        "4. `model.add(base_model)`:\n",
        "   - Adds the pre-trained Xception base model to the sequential model.\n",
        "\n",
        "5. `model.add(BatchNormalization())`:\n",
        "   - Adds a batch normalization layer to normalize the activations of the previous layer.\n",
        "\n",
        "6. `model.add(Dropout(0.45))`:\n",
        "   - Adds a dropout layer with a dropout rate of 0.45 to prevent overfitting by randomly dropping a fraction of input units during training.\n",
        "\n",
        "7. `model.add(Dense(220, activation='relu'))`:\n",
        "   - Adds a fully connected dense layer with 220 units and ReLU activation function.\n",
        "\n",
        "8. `model.add(Dropout(0.25))`:\n",
        "   - Adds another dropout layer with a dropout rate of 0.25.\n",
        "\n",
        "9. `model.add(Dense(60,activation='relu'))`:\n",
        "   - Adds another fully connected dense layer with 60 units and ReLU activation function.\n",
        "\n",
        "10. `model.add(Dense(1, activation='sigmoid'))`:\n",
        "    - Adds the output layer with 1 unit and sigmoid activation function for binary classification.\n",
        "\n",
        "11. `model.compile(optimizer=Adamax(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])`:\n",
        "    - Compiles the model with the Adamax optimizer and a learning rate of 0.001, binary crossentropy loss function for binary classification, and accuracy as the evaluation metric.\n",
        "\n",
        "12. `model.summary()`:\n",
        "    - Prints a summary of the model architecture, including the number of parameters in each layer."
      ],
      "metadata": {
        "id": "3otJ9pNELtoO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Xception base model without the top (classification) layer\n",
        "base_model = Xception(weights='imagenet', include_top=False, pooling='avg', input_shape=(256, 256, 3))\n",
        "\n",
        "# Freeze the layers in the base model\n",
        "base_model.trainable = False\n",
        "\n",
        "# Build Model\n",
        "model = Sequential()\n",
        "\n",
        "# Base Model\n",
        "model.add(base_model)\n",
        "\n",
        "# Batch Normalization\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# Dropout Layer\n",
        "model.add(Dropout(0.45))\n",
        "\n",
        "# Dense Layer 1\n",
        "model.add(Dense(220, activation='relu'))\n",
        "\n",
        "# Dropout Layer\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# Dense Layer 2\n",
        "model.add(Dense(60,activation='relu'))\n",
        "\n",
        "# Output Layer\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile\n",
        "model.compile(optimizer=Adamax(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-03T18:09:10.513594Z",
          "iopub.execute_input": "2024-03-03T18:09:10.514457Z",
          "iopub.status.idle": "2024-03-03T18:09:12.423161Z",
          "shell.execute_reply.started": "2024-03-03T18:09:10.514424Z",
          "shell.execute_reply": "2024-03-03T18:09:12.422305Z"
        },
        "trusted": true,
        "id": "A6E-MOFELtoO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### **<h1 align=\"center\"><span style=\"color:#6A5ACD;\">Compile and Fitting</span>**"
      ],
      "metadata": {
        "id": "rmLIUr6TLtoP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Early_Stopping\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "#Fitting Model\n",
        "history = model.fit_generator(train_ds,\n",
        "                        epochs= 20,\n",
        "                        validation_data = validation_ds,\n",
        "                        callbacks = early_stopping)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-03T18:09:16.142762Z",
          "iopub.execute_input": "2024-03-03T18:09:16.143596Z",
          "iopub.status.idle": "2024-03-03T18:16:27.053601Z",
          "shell.execute_reply.started": "2024-03-03T18:09:16.143564Z",
          "shell.execute_reply": "2024-03-03T18:16:27.052731Z"
        },
        "trusted": true,
        "id": "iePRmassLtoP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### **<h1 align=\"center\"><span style=\"color:#6A5ACD;\">Val Loss and Accuracy</span>**"
      ],
      "metadata": {
        "id": "hKPGe8aFLtoP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the validation dataset\n",
        "validation_loss, validation_accuracy = model.evaluate(validation_ds)\n",
        "\n",
        "# Print the validation loss and accuracy\n",
        "print(\"Validation Loss:\", validation_loss)\n",
        "print(\"Validation Accuracy:\", validation_accuracy)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-03T18:16:36.424196Z",
          "iopub.execute_input": "2024-03-03T18:16:36.431537Z",
          "iopub.status.idle": "2024-03-03T18:16:39.016549Z",
          "shell.execute_reply.started": "2024-03-03T18:16:36.431503Z",
          "shell.execute_reply": "2024-03-03T18:16:39.015613Z"
        },
        "trusted": true,
        "id": "SE2w6tpgLtoP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the epoch with the highest validation accuracy\n",
        "best_epoch = history.history['val_accuracy'].index(max(history.history['val_accuracy'])) + 1\n",
        "\n",
        "# Set the background style\n",
        "plt.style.use('seaborn-darkgrid')\n",
        "\n",
        "# Create a subplot with 1 row and 2 columns\n",
        "fig, axs = plt.subplots(1, 2, figsize=(16, 5))\n",
        "\n",
        "# Plot training and validation accuracy\n",
        "axs[0].plot(history.history['accuracy'], label='Training Accuracy', color='blue')\n",
        "axs[0].plot(history.history['val_accuracy'], label='Validation Accuracy', color='red')\n",
        "axs[0].scatter(best_epoch - 1, history.history['val_accuracy'][best_epoch - 1], color='green', label=f'Best Epoch: {best_epoch}')\n",
        "axs[0].set_xlabel('Epoch')\n",
        "axs[0].set_ylabel('Accuracy')\n",
        "axs[0].set_title('Training and Validation Accuracy')\n",
        "axs[0].legend()\n",
        "\n",
        "# Plot training and validation loss\n",
        "axs[1].plot(history.history['loss'], label='Training Loss', color='blue')\n",
        "axs[1].plot(history.history['val_loss'], label='Validation Loss', color='red')\n",
        "axs[1].scatter(best_epoch - 1, history.history['val_loss'][best_epoch - 1], color='green',label=f'Best Epoch: {best_epoch}')\n",
        "axs[1].set_xlabel('Epoch')\n",
        "axs[1].set_ylabel('Loss')\n",
        "axs[1].set_title('Training and Validation Loss')\n",
        "axs[1].legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-03T18:16:40.35774Z",
          "iopub.execute_input": "2024-03-03T18:16:40.358391Z",
          "iopub.status.idle": "2024-03-03T18:16:40.970487Z",
          "shell.execute_reply.started": "2024-03-03T18:16:40.35836Z",
          "shell.execute_reply": "2024-03-03T18:16:40.969577Z"
        },
        "trusted": true,
        "id": "32FEGOkPLtoP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <p style=\"font-family:newtimeroman;font-size:150%;text-align:center;color:#6A5ACD;\">Model Predictions</p>"
      ],
      "metadata": {
        "id": "Q57g_jnnLtoP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_dir = '/kaggle/input/chest-xray-pneumonia/chest_xray/test/'\n",
        "print('Testing Images:')\n",
        "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    test_dir,\n",
        "    seed=123,\n",
        "    image_size=IMAGE_SIZE,\n",
        "    batch_size=32)\n",
        "\n",
        "# Define a function to plot images with their true and predicted labels\n",
        "def plot_images_with_predictions(model, dataset, class_labels, num_images=40, num_images_per_row=5):\n",
        "    # Generate predictions for a set number of images\n",
        "    predictions = model.predict(dataset)\n",
        "\n",
        "    # Shuffle the dataset\n",
        "    dataset_shuffled = dataset.shuffle(buffer_size=len(dataset))\n",
        "\n",
        "    plt.figure(figsize=(15, 10))\n",
        "    for i, (images, labels) in enumerate(dataset_shuffled.take(num_images)):\n",
        "        # Convert tensor to NumPy array\n",
        "        images = images.numpy()\n",
        "\n",
        "        # Iterate over each image in the batch\n",
        "        for j in range(len(images)):\n",
        "            if i * num_images_per_row + j < num_images:  # Check if the total number of images exceeds the desired count\n",
        "                predicted_class = class_labels[np.argmax(predictions[i * num_images_per_row + j])]\n",
        "                true_class = class_labels[np.argmax(labels[j])]\n",
        "\n",
        "                plt.subplot(num_images // num_images_per_row + 1, num_images_per_row, i * num_images_per_row + j + 1)\n",
        "                plt.imshow(images[j].astype(\"uint8\"))\n",
        "                plt.title(f'True: {true_class}\\nPredicted: {predicted_class}')\n",
        "                plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Visualize predictions on random 20 images from the testing dataset\n",
        "print('Testing Images:')\n",
        "plot_images_with_predictions(model, test_ds, class_labels, num_images=20)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-03T18:16:49.050384Z",
          "iopub.execute_input": "2024-03-03T18:16:49.051088Z",
          "iopub.status.idle": "2024-03-03T18:16:58.758382Z",
          "shell.execute_reply.started": "2024-03-03T18:16:49.051055Z",
          "shell.execute_reply": "2024-03-03T18:16:58.75749Z"
        },
        "trusted": true,
        "id": "g1jppe5FLtoU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to the directory containing the images\n",
        "directory_path = '/kaggle/input/chest-xray-pneumonia/chest_xray/test/PNEUMONIA/'\n",
        "\n",
        "# Select N image files from the directory\n",
        "image_files = os.listdir(directory_path)[:5]\n",
        "\n",
        "# Create a figure and axes for subplots\n",
        "fig, axs = plt.subplots(1, len(image_files), figsize=(15, 5))\n",
        "\n",
        "# Load and preprocess each image, make predictions, and display them using a loop\n",
        "for i, image_file in enumerate(image_files):\n",
        "    img_path = os.path.join(directory_path, image_file)\n",
        "    # Load the image using OpenCV\n",
        "    img = cv2.imread(img_path)\n",
        "    # Resize the image to (256, 256)\n",
        "    img = cv2.resize(img, (256, 256))\n",
        "\n",
        "    # Normalize pixel values\n",
        "    img_array = img.astype(np.float32) / 255.0\n",
        "\n",
        "    # Expand the dimensions to match the input shape expected by the model\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "    # Make predictions\n",
        "    predictions = model.predict(img_array)\n",
        "    actual_prediction = (predictions > 0.5).astype(int)\n",
        "\n",
        "    # Display the image with predicted label\n",
        "    # Convert BGR to RGB for displaying with matplotlib\n",
        "    axs[i].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "    axs[i].axis('off')\n",
        "    if actual_prediction[0][0] == 0:\n",
        "        predicted_label = 'Normal'\n",
        "    else:\n",
        "        predicted_label = 'PNEUMONIA'\n",
        "    axs[i].set_title(f'Predicted: {predicted_label}')\n",
        "\n",
        "# Adjust layout\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-03T18:24:53.775239Z",
          "iopub.execute_input": "2024-03-03T18:24:53.776126Z",
          "iopub.status.idle": "2024-03-03T18:24:54.693691Z",
          "shell.execute_reply.started": "2024-03-03T18:24:53.776093Z",
          "shell.execute_reply": "2024-03-03T18:24:54.692324Z"
        },
        "trusted": true,
        "id": "O_QXIqaXLtoV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}